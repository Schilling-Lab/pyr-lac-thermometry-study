{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4502496-eb86-492e-b228-16869fc0c933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import scipy.io as sio\n",
    "import hypermri.utils.utils_general as utg\n",
    "import hypermri.utils.utils_fitting as utf\n",
    "import hypermri.utils.utils_anatomical as uta\n",
    "import hypermri.utils.utils_spectroscopy as uts\n",
    "import seaborn as sns\n",
    "\n",
    "from hypermri.utils.utils_fitting import def_fit_params, fit_t2_pseudo_inv, fit_freq_pseudo_inv, fit_data_pseudo_inv, fit_func_pseudo_inv, plot_fitted_spectra, basefunc\n",
    "from hypermri.utils.utils_general import get_gmr, calc_sampling_time_axis\n",
    "from hypermri.utils.utils_spectroscopy import apply_lb, multi_dim_linebroadening, get_metab_cs_ppm, generate_fid, get_freq_axis, make_NDspec_6Dspec, freq_to_index, find_npeaks\n",
    "\n",
    "import sys\n",
    "# define paths:\n",
    "sys.path.append('../../')\n",
    "\n",
    "import hypermri.utils.utils_spectroscopy as uts\n",
    "\n",
    "\n",
    "# Autoreload extension so that you dont have to reload the kernel every time something is changed in the hypermri or magritek folders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import Template_Cambridge\n",
    "basepath,savepath = Template_Cambridge.import_all_packages(False,True)\n",
    "def get_colors_from_cmap(cmap_name, N):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    colors = cmap(np.linspace(0, 1, N))\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef078123-2d6e-44be-b27b-37aee9f8dee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "revision_path=r'.../Publication/Revision1/RefittedData/Renal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f71a6-40ac-4798-9800-f032c46af599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_analysis(studyfolder,exam_num,error_thld='both',fit_error_threshold = 3,snr_threshold=5):\n",
    "    animal_id = 'MRE-'+studyfolder\n",
    "    if studyfolder in ['012','014','017']:\n",
    "        raw_file=sio.loadmat(os.path.join(basepath, animal_id,  animal_id+\"_raw_fid_\"+str(exam_num)+\".mat\"))\n",
    "        raw_data=raw_file['raw_data']\n",
    "        dyn_fid = raw_data[0::8, :, 0, 0, :]\n",
    "        all_files_in_dir = os.listdir(os.path.join(savepath,'fit_results_100Hz_400ms/'))\n",
    "        fitted_files = []\n",
    "        for index,file in enumerate(all_files_in_dir):\n",
    "            if file.endswith('.pkl'):\n",
    "                fitted_files.append(file)\n",
    "                #print('Found files ',file)\n",
    "        # sort files by number\n",
    "        fitted_files.sort()\n",
    "        # look for file matching the studyfolder_num\n",
    "        for n in range(len(fitted_files)):\n",
    "            if fitted_files[n].find(str(animal_id)+'_fit_spectra_100Hz_400ms_'+str(exam_num))>=0:\n",
    "                load_file=fitted_files[n]\n",
    "            else:\n",
    "                pass\n",
    "        print('-----')\n",
    "        print('Selected study:',studyfolder)\n",
    "        print('Loading',load_file)\n",
    "\n",
    "    else:\n",
    "        raw_file=sio.loadmat(os.path.join(basepath, animal_id,  animal_id+\"_raw_fid.mat\"))\n",
    "        raw_data=raw_file['raw_data']\n",
    "        dyn_fid = raw_data[0::8, :, 0, 0, :]\n",
    "        all_files_in_dir = os.listdir(os.path.join(savepath,'fit_results_100Hz_400ms/'))\n",
    "        fitted_files = []\n",
    "        for index,file in enumerate(all_files_in_dir):\n",
    "            if file.endswith('.pkl'):\n",
    "                fitted_files.append(file)\n",
    "                #print('Found files ',file)\n",
    "        # sort files by number\n",
    "        fitted_files.sort()\n",
    "        # look for file matching the studyfolder_num\n",
    "        for n in range(len(fitted_files)):\n",
    "            if fitted_files[n].find(str(animal_id)+'_fit_spectra_100Hz_400ms__')>=0:\n",
    "                load_file=fitted_files[n]\n",
    "            else:\n",
    "                pass\n",
    "        print('-----')\n",
    "        print('Selected study:',studyfolder)    \n",
    "    print(load_file)\n",
    "    dyn_spec = np.conj(np.flip(np.fft.fftshift(np.fft.fft(dyn_fid, axis=1), axes=(1,)), axis=1))\n",
    "    input_data = uts.make_NDspec_6Dspec(input_data=dyn_spec, provided_dims=[\"reps\", \"spec\", \"z\",\"chans\"])\n",
    "    fit_results = utg.load_as_pkl(dir_path=os.path.join(savepath,'fit_results_100Hz_400ms/'), filename=load_file, global_vars=globals())\n",
    "    print('Loaded data',savepath+'/'+load_file)\n",
    "    fit_spectrums = fit_results['fit_spectrums']\n",
    "    fit_amps = fit_results['fit_amps']\n",
    "    fit_freqs = fit_results['fit_freqs']\n",
    "    fit_t2s = fit_results['fit_t2s']\n",
    "    fit_params = fit_results['fit_params']\n",
    "    fit_stds=fit_results['fit_stds']\n",
    "\n",
    "        \n",
    "\n",
    "    for chan in range(0,input_data.shape[5]):\n",
    "        fig,axes=plt.subplots(input_data.shape[1],input_data.shape[4],figsize=(15,3))\n",
    "        for slic in range(input_data.shape[1]):\n",
    "            for rep in range(input_data.shape[4]):\n",
    "                ax = axes[slic,rep]\n",
    "                ax.plot(fit_params['freq_range_ppm'],np.abs(np.squeeze(input_data)[:,slic,rep,chan]))\n",
    "                ax.plot(fit_params['freq_range_ppm'],np.abs(np.sum(np.squeeze(fit_spectrums)[:,slic,rep,chan,:],axis=1)))\n",
    "                ax.set_xlim([160,190])\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_title('')\n",
    "                ax.set_xlabel('')\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "        [axes[n,0].set_ylabel('Slice '+str(n)) for n in range(input_data.shape[1])]\n",
    "        [axes[0,n].set_title('Rep '+str(n)) for n in range(input_data.shape[4])]\n",
    "        fig.suptitle('Channel '+str(chan))\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "\n",
    "        \n",
    "        # Frequency difference [Hz]:\n",
    "\n",
    "    freq_diff_hz = np.take(fit_freqs, indices=1, axis=-1) - np.take(fit_freqs, indices=0, axis=-1)\n",
    "\n",
    "    # Frequency difference [ppm]:\n",
    "    freq_diff_ppm = uts.freq_Hz_to_ppm(freq_Hz  = freq_diff_hz,\n",
    "                                       hz_axis  = fit_params[\"freq_range_Hz\"],\n",
    "                                       ppm_axis = fit_params['freq_range_ppm'],\n",
    "                                       ppm_centered_at_0=True)\n",
    "\n",
    "    # Temperature [Hz]:\n",
    "    temp, _ = utf.temperature_from_frequency(frequency=freq_diff_ppm,\n",
    "                                             calibration_type='5mM',\n",
    "                                             frequency_is_ppm=True)\n",
    "\n",
    "    # std[freq difference [Hz]] [0/1 = pyr/lac, 1=freqs]\n",
    "    freq_diff_hz_std = np.sqrt(fit_stds[..., 0, 1]**2 +\n",
    "                               fit_stds[..., 1, 1]**2 )\n",
    "\n",
    "    freq_diff_ppm_std = uts.freq_Hz_to_ppm(freq_Hz=freq_diff_hz_std,\n",
    "                                       hz_axis  = fit_params[\"freq_range_Hz\"],\n",
    "                                       ppm_axis = fit_params['freq_range_ppm'],\n",
    "                                       ppm_centered_at_0=True)\n",
    "\n",
    "\n",
    "    temp_plus_std, _ = utf.temperature_from_frequency(frequency=freq_diff_ppm+freq_diff_ppm_std,\n",
    "                                             calibration_type='5mM',\n",
    "                                             frequency_is_ppm=True)\n",
    "\n",
    "    temp_std = np.abs(temp_plus_std - temp)\n",
    "    \n",
    "    \n",
    "    ## SNR masking\n",
    "    snr,noise=uts.compute_snr_from_fit(input_data,fit_spectrums)\n",
    "\n",
    "    snr_mask_cond = (snr[..., 0] < snr_threshold) | (snr[..., 1] < snr_threshold)\n",
    "    snr_mask = np.where(snr_mask_cond, np.nan, 1)\n",
    "    snr_masked_temp=snr_mask*temp\n",
    "\n",
    "\n",
    "    ## Fit error masking\n",
    "    fit_error_mask=np.where(temp_std <= fit_error_threshold, 1, np.nan)\n",
    "    fit_error_masked_temp=np.where(~np.isnan(fit_error_mask), temp, np.nan)\n",
    "\n",
    "\n",
    "    # combine and report all three variants: 1. SNR masked, 2. Fit error masked and 3. combined\n",
    "    snr_and_fit_error_masked_temp=snr_mask*fit_error_masked_temp\n",
    "\n",
    "    def get_mean_t(masked_T):\n",
    "        mean_t_per_slice=np.nanmean(np.squeeze(masked_T),axis=1)\n",
    "        d_mean_t_per_slice=np.nanstd(np.squeeze(masked_T),axis=1)\n",
    "        return mean_t_per_slice,d_mean_t_per_slice\n",
    "    \n",
    "    if error_thld=='both':\n",
    "        mean_t_per_slice,d_mean_t_per_slice=get_mean_t(snr_and_fit_error_masked_temp)\n",
    "        masked_T=snr_and_fit_error_masked_temp\n",
    "        inverse_masked_T=np.where(np.isnan(snr_and_fit_error_masked_temp), temp, np.nan)\n",
    "    elif error_thld=='SNR':\n",
    "        mean_t_per_slice,d_mean_t_per_slice=get_mean_t(snr_masked_temp)\n",
    "        masked_T=snr_masked_temp\n",
    "        inverse_masked_T=np.where(np.isnan(snr_masked_temp), temp, np.nan)\n",
    "    elif error_thld=='fiterror':\n",
    "        mean_t_per_slice,d_mean_t_per_slice=get_mean_t(fit_error_masked_temp)\n",
    "        masked_T=fit_error_masked_temp\n",
    "        inverse_masked_T=np.where(np.isnan(fit_error_masked_temp), temp, np.nan)\n",
    "    else:\n",
    "        raise KeyError(\"Error thresholding must be selected\")\n",
    "    colors = get_colors_from_cmap('tab10', 10)\n",
    "    for chan in range(input_data.shape[5]):\n",
    "        fig,ax=plt.subplots(3,input_data.shape[1],figsize=(10,5),tight_layout=True)\n",
    "\n",
    "        for n in range(input_data.shape[1]):\n",
    "\n",
    "            ax[0,n].plot(inverse_masked_T[0,n,0,0,:,chan],'o',markersize=3,color='r',label='Excluded points')\n",
    "            ax[0,n].plot(masked_T[0,n,0,0,:,chan],'o',markersize=3,color=colors[0])\n",
    "\n",
    "            ax[1,n].plot(np.abs(temp_std[0,n,0,0,:,chan]),'o',markersize=3,color=colors[1])\n",
    "            ax[2,n].plot(np.abs(freq_diff_hz_std[0,n,0,0,:,chan]),'o',markersize=3,color=colors[2])\n",
    "            ax[1,n].hlines(3,0,15,linestyle='dashed',color='g')\n",
    "            ax[2,n].hlines(1,0,15,linestyle='dashed',color='g')\n",
    "\n",
    "\n",
    "            ax[0,n].set_ylim([20,45])\n",
    "            ax[0,n].set_title('Slice '+str(n)+', T='+str(np.round(mean_t_per_slice[n,chan],1))+'±'+str(np.round(d_mean_t_per_slice[n,chan],1))+r'$^\\circ$C')\n",
    "            ax[2,n].set_xlabel('Repetition')\n",
    "            ax[0,n].set_ylabel(r'T[$^\\circ$C]')\n",
    "            ax[1,n].set_ylabel(r'dT[$^\\circ$C]')\n",
    "            ax[2,n].set_ylabel(r'df[Hz]')\n",
    "            ax[0,n].legend(fontsize=6)\n",
    "\n",
    "        fig.suptitle('MRE-'+str(studyfolder)+' Temperature filtered')\n",
    "\n",
    " \n",
    "        \n",
    "    pyr_amp=np.abs(np.squeeze(fit_amps[:,:,:,:,:,:,0]))\n",
    "    lac_amp=np.abs(np.squeeze(fit_amps[:,:,:,:,:,:,1]))\n",
    "\n",
    "    d_pyr_amp = np.squeeze(fit_stds[..., 0, 0])\n",
    "    d_lac_amp = np.squeeze(fit_stds[..., 1, 0])\n",
    "\n",
    "    sum_pyr=np.sum(pyr_amp,axis=1)\n",
    "    sum_lac=np.sum(lac_amp,axis=1)\n",
    "\n",
    "\n",
    "    d_sum_pyr = np.sqrt(np.sum(d_pyr_amp**2, axis=1)) \n",
    "    d_sum_lac = np.sqrt(np.sum(d_lac_amp**2, axis=1)) \n",
    "\n",
    "    AUCR=sum_lac/sum_pyr\n",
    "\n",
    "    d_AUCR = np.abs(AUCR * np.sqrt((d_sum_pyr / sum_pyr)**2 + (d_sum_lac / sum_lac)**2))\n",
    "\n",
    "\n",
    "    for chan in range(input_data.shape[5]):\n",
    "        fig,ax=plt.subplots(input_data.shape[1],1,tight_layout=True,figsize=(5,7))\n",
    "        for slic in range(input_data.shape[1]):\n",
    "            ax[slic].errorbar(np.arange(0,input_data.shape[4],1),pyr_amp[slic,:,chan]/np.max(pyr_amp[slic,:,chan]),yerr=np.abs(d_pyr_amp[slic,:,chan])/np.max(pyr_amp[slic,:,chan]),label='Pyruvate')\n",
    "            ax[slic].errorbar(np.arange(0,input_data.shape[4],1),lac_amp[slic,:,chan]/np.max(pyr_amp[slic,:,chan]),yerr=np.abs(d_lac_amp[slic,:,chan])/np.max(pyr_amp[slic,:,chan]),label='Lactate')\n",
    "            ax[slic].set_ylabel('Slice '+str(slic))\n",
    "            ax[slic].legend()\n",
    "            ax[slic].set_xlabel('Repetition')\n",
    "            ax[slic].set_title('AUCR='+str(np.round(AUCR[slic,chan],1))+'±'+str(np.round(d_AUCR[slic,chan],3)))\n",
    "        fig.suptitle('MRE-'+str(studyfolder)+', chan '+str(chan))\n",
    "\n",
    "\n",
    "    data = {'ID':[],'exam':[],'slice': [], 'channel': [], 'T': [], 'dT': [], 'AUCR': [], 'dAUCR': [],'nT':[]}\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for s in range(input_data.shape[1]):  # Row index (0–4)\n",
    "        for c in range(input_data.shape[5]):  # Column index (0–7)\n",
    "            data['ID'].append('MRE-'+str(studyfolder))\n",
    "            data['exam'].append(exam_num)\n",
    "            data['nT'].append((~np.isnan(masked_T[0,s,0,0,:,c])).sum())\n",
    "            data['slice'].append(s)\n",
    "            data['channel'].append(c)\n",
    "            data['T'].append(mean_t_per_slice[s][c])\n",
    "            data['dT'].append(d_mean_t_per_slice[s][c])\n",
    "            data['AUCR'].append(AUCR[s][c])\n",
    "            data['dAUCR'].append(d_AUCR[s][c])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(revision_path+'MRE-'+studyfolder+'_'+str(exam_num)+'_results_thld_snr_fit.xlsx')\n",
    "    print('Saved df to ',revision_path+'MRE-'+studyfolder+'_'+str(exam_num)+'_results_thld_snr_fit.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9766de7-c5fe-4b1f-ab1e-32e3df41062b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "studyfolder_nums = ['001','006','008','010','012','013','014','016','017','019','020','023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e05bb-a17e-4b74-ade6-6511555f67d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for studyfolder in studyfolder_nums:\n",
    "    if studyfolder in ['012','014']:\n",
    "        for exam_num in range(1,3):\n",
    "            perform_analysis(studyfolder,exam_num)\n",
    "    else:\n",
    "        perform_analysis(studyfolder,exam_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8fcf9-dafa-46c8-99bc-cf4dcaefd75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
